{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select the GPU, you can skip this part\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "conv1 = Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape)\n",
    "model.add(conv1)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu')\n",
    "model.add(conv2)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train part\n",
    "# can be train several times depends on demand\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          # epochs=3,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_acc():\n",
    "    global model\n",
    "    # evaluation part\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    # print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the selection of the part of the kernel filter varies in stage of the experiments\n",
    "def hash_3x3(filter:np.array) -> np.array:\n",
    "    return np.int32(np.array([filter[0,0], filter[0,1], filter[0,2], filter[1,0], filter[2, 0]])\n",
    "                              * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 1 starts from here\n",
    "# be sure to retrain the model or to store and restore the weight matrix for the original accuracy.\n",
    "conv1w, conv1b = conv1.get_weights()\n",
    "conv2w, conv2b = conv2.get_weights()\n",
    "hash_matrix_l1 = np.zeros((conv1w.shape[3], conv1w.shape[2], 5), dtype=np.int32)\n",
    "hash_matrix_l2 = np.zeros((conv2w.shape[3], conv2w.shape[2], 5), dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(32):\n",
    "    hash_matrix_l1[i][0] = (hash_3x3(conv1w[:,:,0,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(64):\n",
    "    for j in range(32):\n",
    "        hash_matrix_l2[i][j] = (hash_3x3(conv2w[:,:,j,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# conv2b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace weights in layer 1 by layer 2\n",
    "for i1 in range(conv1w.shape[3]):\n",
    "    # conv1\n",
    "    next_i = 0\n",
    "    min_ = 1000\n",
    "    idx = []\n",
    "    for i2 in range(64):\n",
    "        for j2 in range(32):\n",
    "            tmp = np.sum(np.abs(hash_matrix_l1[i1][0] - hash_matrix_l2[i2][j2]))\n",
    "            if (tmp < min_):\n",
    "                min_ = tmp\n",
    "                idx = [i2, j2]\n",
    "            if (min_ < 100):\n",
    "                # print(i1, i2, j2, tmp)\n",
    "                conv1w[:,:,0,i1] = conv2w[:,:,j2,i2]\n",
    "                next_i = 1\n",
    "                break\n",
    "        if (next_i == 1):\n",
    "            break\n",
    "    if (next_i == 0):\n",
    "        # print(i1, idx, min_)\n",
    "        if (min_ < 250): # should be determined manually\n",
    "            conv1w[:,:,0,i1] = conv2w[:,:,idx[1],idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1.set_weights([conv1w, conv1b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"After weight replacement\")\n",
    "print_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# end of experiment 1 #####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test part, you can ignore this part\n",
    "for c in range(31):\n",
    "    # layer 2; channel c, c+1;\n",
    "    for i in range(64):\n",
    "        for j in range(64):\n",
    "            for k in range(4):\n",
    "                tmp += np.abs(hash_matrix_l2[i][c][k] - hash_matrix_l2[j][c+1][k])\n",
    "                if (tmp > 50):\n",
    "                    break\n",
    "            if tmp < 50:\n",
    "                print(c, i, j, tmp)\n",
    "                next_l = 1\n",
    "                conv2w[:,:,c,i] = conv2w[:,:,c+1,j]\n",
    "                break\n",
    "                # max_ = tmp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 2\n",
    "# train again for second method experiment\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can start experiment 2 from here. \n",
    "num_basis = 6 # it's tunable\n",
    "a_s = np.zeros((32, num_basis))\n",
    "basis = np.random.rand(num_basis,3,3) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1w, conv1b = conv1.get_weights()\n",
    "conv2w, conv2b = conv2.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_all(a, b):\n",
    "        tmp = np.zeros((b.shape[1], b.shape[2]))\n",
    "        for i in range(b.shape[0]):\n",
    "            tmp += a[i] * b[i,:,:]\n",
    "        return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_efficients(basis:np.array, target:np.array) -> np.array:\n",
    "    res = (np.random.rand(basis.shape[0]) - 0.5) / 10\n",
    "    loss = np.sum(np.square(target - sum_all(res, basis)))\n",
    "    \n",
    "    # gradient descent method\n",
    "    dres = np.zeros(basis.shape[0])\n",
    "    lr = 0.3\n",
    "    j = 0 # iteration times\n",
    "    # print(loss)\n",
    "    while(j < 300):\n",
    "        tmp_y = sum_all(res, basis)\n",
    "        for i in range(basis.shape[0]):\n",
    "            '''\n",
    "            dres[i] = 0\n",
    "            for ii in range(3):\n",
    "                for jj in range(3):\n",
    "                    dres[i] += 2 * (target[ii][jj] - tmp_y[ii][jj]) * (-basis[i][ii][jj])\n",
    "            '''\n",
    "            dres[i] = np.sum(2 * (target - tmp_y) * (-basis[i]))\n",
    "        # print(dres)\n",
    "        # print(res)\n",
    "        res -= lr * dres\n",
    "        # print(target - sum_all(res, basis))\n",
    "        loss = np.sum(np.square(target - sum_all(res, basis)))\n",
    "        # print(loss)\n",
    "        if (loss < 1e-5):\n",
    "            break\n",
    "        j += 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_effs(basis, target):\n",
    "    A = np.zeros((9,9), dtype = np.float32)\n",
    "    for i in range(9):\n",
    "        A[i] = basis[i].reshape(9,)\n",
    "    return np.matmul(target.reshape(9,), np.linalg.inv(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(conv1w[:,:,0,1] - sum_all(get_efficients(basis, conv1w[:,:,0,1]), basis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(32):\n",
    "    a_s[i] = get_efficients(basis, conv1w[:,:,0,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(conv1w[:,:,0,1] - sum_all(a_s[1], basis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reconstruct the network\n",
    "input_layer = keras.Input(shape=input_shape) # begin to split the first layer into two layers\n",
    "l = Conv2D(num_basis, kernel_size=(3, 3))(input_layer) # be careful that the activation should be linear rather than relu\n",
    "x = Conv2D(32, kernel_size=(1, 1), activation='relu')(l)\n",
    "for i in range(1, 8):\n",
    "    x = model.layers[i](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = keras.Model(input=input_layer, output=x)\n",
    "# new_model.summary()\n",
    "new_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1_1w, conv1_1b = new_model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_basis):\n",
    "    conv1_1w[:,:,0,i] = basis[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conv1_1b has been set to 0 initailly\n",
    "new_model.layers[1].set_weights([conv1_1w, conv1_1b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1_2w, conv1_2b = new_model.layers[2].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(32):\n",
    "    for j in range(num_basis):\n",
    "        conv1_2w[:,:,j,i] = a_s[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_model.layers[2].set_weights([conv1_2w, conv1b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = new_model.evaluate(x_test, y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "print(\"After weight reconstruction\")\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 tf_env",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
